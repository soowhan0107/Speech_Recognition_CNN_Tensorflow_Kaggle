{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "#Scientific Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from scipy.misc import imread\n",
    "\n",
    "# Visualization Library\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 classes from the list : \n",
    "yes, no, up, down, left, right, on, off, stop, go\n",
    "\n",
    "2 classes below :\n",
    "1. 6 pictures from silence\n",
    "2. everything else to unknown\n",
    "\n",
    "Take 400 pictures from each class above - 4000 total\n",
    "and from the rest of 20 classes, take 20 pictures from each - 400 pictures for unknown\n",
    "\n",
    "Possible Data Augmentation on 6 pictures for silence\n",
    "\n",
    "-> for now, total of 4000 + 400 + 6 = 4406 pictures.\n",
    "Everything in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = os.listdir('../input/audio/cat')\n",
    "down = os.listdir('../input/audio/down')\n",
    "four = os.listdir('../input/audio/four')\n",
    "house = os.listdir('../input/audio/house')\n",
    "nine = os.listdir('../input/audio/nine')\n",
    "on = os.listdir('../input/audio/on')\n",
    "seven = os.listdir('../input/audio/seven')\n",
    "stop = os.listdir('../input/audio/stop')\n",
    "two = os.listdir('../input/audio/two')\n",
    "yes = os.listdir('../input/audio/yes')\n",
    "bed = os.listdir('../input/audio/bed')\n",
    "eight = os.listdir('../input/audio/eight')\n",
    "go = os.listdir('../input/audio/go')\n",
    "left = os.listdir('../input/audio/left')\n",
    "no = os.listdir('../input/audio/no')\n",
    "one = os.listdir('../input/audio/one')\n",
    "sheila = os.listdir('../input/audio/sheila')\n",
    "three = os.listdir('../input/audio/three')\n",
    "up = os.listdir('../input/audio/up')\n",
    "zero = os.listdir('../input/audio/zero')\n",
    "bird = os.listdir('../input/audio/bird')\n",
    "dog = os.listdir('../input/audio/dog')\n",
    "five = os.listdir('../input/audio/five')\n",
    "happy = os.listdir('../input/audio/happy')\n",
    "marvin = os.listdir('../input/audio/marvin')\n",
    "off = os.listdir('../input/audio/off')\n",
    "right = os.listdir('../input/audio/right')\n",
    "six = os.listdir('../input/audio/six')\n",
    "tree = os.listdir('../input/audio/tree')\n",
    "wow = os.listdir('../input/audio/wow')\n",
    "silence = os.listdir('../input/audio/silence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2377\n"
     ]
    }
   ],
   "source": [
    "print(len(yes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by doing ls -R | wc -l, found out there are total of 64823 spectrogram. We will put in 100 from each first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.empty((100,129,256), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index=0\n",
    "#image_name_list = sheila\n",
    "#for image_name in image_name_list[:100]:\n",
    "#    imageA = plt.imread('../input/audio/sheila/' + image_name)\n",
    "#    data[index] = imageA\n",
    "#    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=P size=50x50 at 0x7F4CDFC4C8D0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "a=Image.open('../input/audio/sheila/' + sheila[9]).resize((50,50))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Yes Spectrogram Images to Pixels\n",
    "\n",
    "data = np.empty((4800,50,50), dtype=np.float32)\n",
    "\n",
    "# top 10\n",
    "\n",
    "index = 0\n",
    "image_name_list = yes\n",
    "for image_name in image_name_list[:400]:\n",
    "    imageA = Image.open('../input/audio/yes/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = no\n",
    "for image_name in image_name_list[:400]:\n",
    "    imageA = Image.open('../input/audio/no/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "        \n",
    "image_name_list = up\n",
    "for image_name in image_name_list[:400]:\n",
    "    imageA = Image.open('../input/audio/up/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = down\n",
    "for image_name in image_name_list[:400]:\n",
    "    imageA = Image.open('../input/audio/down/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = left\n",
    "for image_name in image_name_list[:400]:\n",
    "    imageA = Image.open('../input/audio/left/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = right\n",
    "for image_name in image_name_list[:400]:\n",
    "    imageA = Image.open('../input/audio/right/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = on\n",
    "for image_name in image_name_list[:400]:\n",
    "    imageA = Image.open('../input/audio/on/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = off\n",
    "for image_name in image_name_list[:400]:\n",
    "    imageA = Image.open('../input/audio/off/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = stop\n",
    "for image_name in image_name_list[:400]:\n",
    "    imageA = Image.open('../input/audio/stop/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = go\n",
    "for image_name in image_name_list[:400]:\n",
    "    imageA = Image.open('../input/audio/go/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "# Top 10 done\n",
    "\n",
    "# Silence 400 pictures\n",
    "    \n",
    "image_name_list = silence\n",
    "for image_name in image_name_list:\n",
    "    imageA = Image.open('../input/audio/silence/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1    \n",
    "\n",
    "# Unknown : 20 pictures from the rest\n",
    "    \n",
    "image_name_list = cat\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/cat/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "     \n",
    "image_name_list = four\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/four/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = house\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/house/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = nine\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/nine/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = seven\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/seven/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = two\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/two/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "\n",
    "image_name_list = bed\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/bed/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = eight\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/eight/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = one\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/one/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = sheila\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/sheila/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = three\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = plt.imread('../input/audio/three/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = zero\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/zero/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = bird\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/bird/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = dog\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/dog/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = five\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/five/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = happy\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/happy/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = marvin\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/marvin/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1 \n",
    "    \n",
    "image_name_list = six\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/six/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = tree\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/tree/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = wow\n",
    "for image_name in image_name_list[:20]:\n",
    "    imageA = Image.open('../input/audio/wow/' + image_name).resize((50,50))\n",
    "    data[index] = imageA\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 50, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4800 data sets with 30 classes and 100 spectrograms in each class\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.,   4.,   4., ...,  13.,  13.,   4.],\n",
       "       [  8.,   4.,   6., ...,  14.,  17.,   4.],\n",
       "       [ 10.,   4.,  20., ...,   4.,  12.,  16.],\n",
       "       ...,\n",
       "       [ 56.,  59.,  53., ...,  67.,  70.,  54.],\n",
       "       [ 78.,  73.,  79., ...,  82.,  78.,  70.],\n",
       "       [129., 133., 132., ..., 127., 123., 128.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the end is not empty meaning that 3000 has all been transferred\n",
    "data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4cad0874a8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show one image\n",
    "plt.imshow(data[456])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten\n",
    "# 50, 50 -> 2500\n",
    "#single_image = data[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_image = single_image.reshape(129, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_df = pd.DataFrame(single_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_df = random_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_df[-1] = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min of pixel : 0.015686275\n",
      "max of pixel : 0.7529412\n"
     ]
    }
   ],
   "source": [
    "print(\"min of pixel : \" + str(data[0].min()))\n",
    "print(\"max of pixel : \" + str(data[0].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#concatenate all the flattened spectrograms in order\n",
    "fl_data = np.empty((4800,2500), dtype=np.float32)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    flat = data[i].flatten()\n",
    "    fl_data[i] = flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size : (4800, 2500)\n",
      "[0.01568628 0.01568628 0.01568628 ... 0.49803922 0.48235294 0.5019608 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check if transferred all\n",
    "print(\"size : \" + str(fl_data.shape))\n",
    "print(fl_data[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(30):\n",
    "#    print(i % 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique\n",
    "def unique(list1): \n",
    "  \n",
    "    # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in list1: \n",
    "        # check if exists in unique_list or not \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x)\n",
    "    # print list \n",
    "    for x in unique_list: \n",
    "        print (x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "label = np.zeros((400,), dtype=int)\n",
    "\n",
    "for i in range(1, 12):\n",
    "    label = np.concatenate((label, np.repeat(i, 400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# check uniques\n",
    "unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800,)\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print(label.shape)\n",
    "print(type(label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#one hot encode the lable\n",
    "b = np.zeros((label.size, label.max()+1))\n",
    "b[np.arange(label.size), label] = 1\n",
    "labels = b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 2500)\n",
      "(4800, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(fl_data.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check on prepared datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 2500)\n",
      "(4800,)\n"
     ]
    }
   ],
   "source": [
    "print(fl_data.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before dividing into train and test sets, let's combine so we can shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 2512)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.concatenate((fl_data, labels), axis=1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle\n",
    "np.random.shuffle(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 12)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to slice the labels again\n",
    "new_labels=a[:,-12:]#.sum()\n",
    "new_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 2500)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to slice the train again\n",
    "train_data=a[:,:2500]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#x_train, x_val, y_train, y_val = train_test_split(data, labels, test_size = 0.2)\n",
    "#x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : (4000, 2500)\n",
      "train validation : (800, 2500)\n",
      "train label : (4000, 12)\n",
      "train validation label : (800, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = train_data[:4000]\n",
    "print(\"train : \" + str(x_train.shape))\n",
    "x_val = train_data[4000:]\n",
    "print(\"train validation : \" + str(x_val.shape))\n",
    "y_train = new_labels[:4000]\n",
    "print(\"train label : \" + str(y_train.shape))\n",
    "y_val = new_labels[4000:]\n",
    "print(\"train validation label : \" + str(y_val.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#change data types to df\\nx_train = pd.DataFrame(x_train)\\nx_validation = pd.DataFrame(x_validation)\\ny_train = pd.DataFrame(y_train)\\ny_validation = pd.DataFrame(y_validation)\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#change data types to df\n",
    "x_train = pd.DataFrame(x_train)\n",
    "x_validation = pd.DataFrame(x_validation)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_validation = pd.DataFrame(y_validation)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train[:2][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 2500)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Helper f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight initialization function\n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return (tf.Variable(init_random_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias initialization function\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d convolution function which is already performed by tf\n",
    "def conv2d(x, W):\n",
    "    # x => input tensor ==> [batch, H, W, Channels]\n",
    "    # W => kernel => [filter height, filter width, # of channels in, # channels out]\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1],padding=\"SAME\")\n",
    "# padding with SAME adds zeros to the end\n",
    "# Strides is how you want to move in the whole thing [batch, height, width, channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling function in this case max pooling which gets the max value and is a 2x2 kernel\n",
    "def max_pool_2by2(x):\n",
    "    # x=> input => [batch, h, w, c]\n",
    "    return (tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\"))\n",
    "# Ksize = size of the window which makces the pooling [batch, h, w, c] => here 1 is like pasing all 2 is reducing\n",
    "    # We only want to reduce the height and width of the image, that is why we use \n",
    "    # [1 in batch, 2 in height, 2 in width, 1 in channel]\n",
    "#  Stride here is [1, 2, 2, 1] because we want to shorten the image so we jump 2 by 2 pixels in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional layer function\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]]) \n",
    "    # we take the third one because that is the number of channels we are using\n",
    "    # is not really intuitive but the channels is like the number of features\n",
    "    # first is going to be 1 then more\n",
    "    return (tf.nn.relu(conv2d(input_x, W)+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal layaer (fully connected layer)\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1]) \n",
    "    # we use the index one beacause 0 is the batch size and 1 is the number of nodes\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return (tf.matmul(input_layer, W)+b)\n",
    "# simple weighted sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 2500])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, 50, 50, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x_image, shape=[25,25,1,4])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling, shape=[12,12,4,4])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_3 = convolutional_layer(convo_2_pooling, shape=[6,6,4,4])\n",
    "convo_3_pooling = max_pool_2by2(convo_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_3_pooling,[-1, 1960])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat, 100*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y_true,1))\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "tf.summary.scalar(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable initializer\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#savers\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summaries for tensorboard\n",
    "merged_summary_op = tf.summary.merge_all() # this will get all the summaries from the graph and join them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[{{node Placeholder_2}} = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_2', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-55-9ba37e570df2>\", line 1, in <module>\n    hold_prob = tf.placeholder(tf.float32)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 1745, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 5020, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[{{node Placeholder_2}} = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[{{node Placeholder_2}} = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-e6b44a22e6c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             summary = sess.run(merged_summary_op,\n\u001b[0;32m---> 22\u001b[0;31m                                       {x:x_train[rand_ind], y_true:y_train[rand_ind], hold_prob:1.0})\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1306\u001b[0m           self._config.experimental.client_handles_error_formatting):\n\u001b[1;32m   1307\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[{{node Placeholder_2}} = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_2', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-55-9ba37e570df2>\", line 1, in <module>\n    hold_prob = tf.placeholder(tf.float32)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 1745, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 5020, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[{{node Placeholder_2}} = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "steps = 1000\n",
    "batch_size = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # to use tensorboard you need to have a file writer to keep the logs\n",
    "    train_writer = tf.summary.FileWriter(\"./tensorboard/train\", graph=tf.get_default_graph())\n",
    "    validation_writer = tf.summary.FileWriter(\"./tensorboard/validation\", graph=tf.get_default_graph())\n",
    "    \n",
    "    for i in range(steps + 1):\n",
    "        \n",
    "        rand_ind = np.random.randint(len(x_train), size=batch_size)\n",
    "        # Here we add hold_prob to our feed dictionary because it is a placeholder\n",
    "        feed = {x:x_train[rand_ind], y_true:y_train[rand_ind], hold_prob:0.6}\n",
    "        sess.run(train, feed_dict=feed)\n",
    "        \n",
    "        \n",
    "        # When runnining you need to append logs for tensorboard\n",
    "        if i%100 == 0:\n",
    "            summary = sess.run(merged_summary_op,\n",
    "                                      {x:x_train[rand_ind], y_true:y_train[rand_ind], hold_prob:1.0})\n",
    "            train_writer.add_summary(summary, i)\n",
    "            train_writer.flush()\n",
    "            summary = sess.run(merged_summary_op,\n",
    "                                      {x:x_val, y_true:y_val, hold_prob:1.0})\n",
    "            validation_writer.add_summary(summary, i)\n",
    "            validation_writer.flush()\n",
    "            print(\"tensorboard summary at #{}\".format(i))\n",
    "    \n",
    "    saver.save(sess, \"cnn_model/cnn.ckpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = np.empty((158538,50,50), dtype=np.float32)\n",
    "test_data = np.empty((1000,50,50), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = os.listdir('../input/audio_test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "image_name_list = test\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = Image.open('../input/audio_test/' + image_name).resize((50,50))\n",
    "    test_data[index] = imageA\n",
    "    index+=1\n",
    "    if index%1000==0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_test_data = np.empty((1000,2500), dtype=np.float32)\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    flat = test_data[i].flatten()\n",
    "    fl_test_data[i] = flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"cnn_model/cnn.ckpy\")\n",
    "    \n",
    "    prediction = y_pred\n",
    "    predictions = sess.run(prediction, feed_dict={x:fl_test_data, hold_prob:1.0})\n",
    "    result = []\n",
    "    decode = tf.argmax(predictions, axis=1)\n",
    "    result = sess.run(decode)\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
