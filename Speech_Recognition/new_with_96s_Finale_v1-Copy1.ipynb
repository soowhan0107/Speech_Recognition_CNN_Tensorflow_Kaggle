{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "\n",
    "#Scientific Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from scipy.misc import imread\n",
    "from sklearn import metrics\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "# Visualization Library\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 classes from the list : \n",
    "yes, no, up, down, left, right, on, off, stop, go\n",
    "\n",
    "2 classes below :\n",
    "1. 6 pictures from silence * randomly selected multiplication to equal 400 -> 100 (penalize).\n",
    "2. everything else to unknown\n",
    "\n",
    "Take 200 pictures from each class above - 2000 total\n",
    "and from the rest of 20 classes, take 100 pictures from each - 2000 pictures for unknown\n",
    "\n",
    "Possible Data Augmentation on 6 pictures for silence = 400 -> 50\n",
    "\n",
    "-> for now, total of 2000 + 2000 + 50 = 4050 pictures.\n",
    "Everything in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = os.listdir('../input/audio/cat')\n",
    "down = os.listdir('../input/audio/down')\n",
    "four = os.listdir('../input/audio/four')\n",
    "house = os.listdir('../input/audio/house')\n",
    "nine = os.listdir('../input/audio/nine')\n",
    "on = os.listdir('../input/audio/on')\n",
    "seven = os.listdir('../input/audio/seven')\n",
    "stop = os.listdir('../input/audio/stop')\n",
    "two = os.listdir('../input/audio/two')\n",
    "yes = os.listdir('../input/audio/yes')\n",
    "bed = os.listdir('../input/audio/bed')\n",
    "eight = os.listdir('../input/audio/eight')\n",
    "go = os.listdir('../input/audio/go')\n",
    "left = os.listdir('../input/audio/left')\n",
    "no = os.listdir('../input/audio/no')\n",
    "one = os.listdir('../input/audio/one')\n",
    "sheila = os.listdir('../input/audio/sheila')\n",
    "three = os.listdir('../input/audio/three')\n",
    "up = os.listdir('../input/audio/up')\n",
    "zero = os.listdir('../input/audio/zero')\n",
    "bird = os.listdir('../input/audio/bird')\n",
    "dog = os.listdir('../input/audio/dog')\n",
    "five = os.listdir('../input/audio/five')\n",
    "happy = os.listdir('../input/audio/happy')\n",
    "marvin = os.listdir('../input/audio/marvin')\n",
    "off = os.listdir('../input/audio/off')\n",
    "right = os.listdir('../input/audio/right')\n",
    "six = os.listdir('../input/audio/six')\n",
    "tree = os.listdir('../input/audio/tree')\n",
    "wow = os.listdir('../input/audio/wow')\n",
    "silence = os.listdir('../input/audio/silence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2377\n"
     ]
    }
   ],
   "source": [
    "print(len(yes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by doing ls -R | wc -l, found out there are total of 64823 spectrogram. We will put in 100 from each first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.empty((100,129,256), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index=0\n",
    "#image_name_list = sheila\n",
    "#for image_name in image_name_list[:100]:\n",
    "#    imageA = plt.imread('../input/audio/sheila/' + image_name)\n",
    "#    data[index] = imageA\n",
    "#    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGAAAABgCAIAAABt+uBvAABASElEQVR4nE28V5MlSZKl96mZs8vvDZ6RkTyrsjKzSFd3V091D+nhM4tZWWAh+7APkBX8EPwGCJ4gggf8gBUAsrKDlcWSmemZ7mla1cWzkpPIDE4uJ87MFA83fGXiMeKGX3dzU7WjR89RUXUgoDCGY2hBB0KYwQy2IIAcxgAcwHX4DbwLAsdwDTowhAY4yKAPBdyEFxDDGtTBgwEBQGEAQAGr8DcQwY9hBmdws/rMERxXv7kMBhxYeAMtOIF1WAUPDkJIYQJAAlPYAmD5dDN4Bm3YhBiAGF7AOlhQqIMBhSlEkEEAFgYBZBDCFEqQ6g+7sAMtEJjCKeTQhQ2I4TqMIYMmKEzgFBIYgYcNSMCDgoUjWIM2ZCAQg0IMI0ihDt+FAiawgD5cAwMp5LADPShgDgIFtGEb3sARbMNTAK7BuPrACqTQAq3esUAN3oYp1CCHHGbQhQBKUMghAAFTLdkRRICBGCyEkIGBEWQwgDEU4OEARtCGqHrCSzCAEi5DB+ZQQABdSMCChTFE0IISZtV7HoKCgRrEUMIBrEIdnkMCV+Eh9KGEteqCTTgCrR4ggR34AJpQwAAKOIMUamCgVy1QCD3oQBPq1dst4BT6oBBBHU7gBEow1fKloMuNFoCp/hbCKoTgIYEYkurVXYMFHMA6ACFcqwLBwwo0YAp1yOAUrlS3EsB1mEMJNbCQQgoJKGxWCxrCJtjqlcYQggUDAQQwAqBdxbuFFTDwDkwhB4EehFUkTqAFy/iowwTOYAPCapfl1QqWALyq8sAIkuqtWBgHAAyq8M6rG1o+6hgOIYE+nEIHAjiCevX/EUzAgYM55NCAAo5hvXoVLWhBBikYmMIzuAOdKh1otd3G4CAG/0/CYQSrEFQ7fQETKKBRvYMT2IIS5tW/p9ADCyWU4GAMHYhAoQYhzKtgX0AXDHg4hjZ4sFCHBcQGgAia1S2egEIXStiDLlwCDx1I0b+GXTiHOcyqYCwghxacwS5k4KGASyDgYRnLz2EENbgPBRSwgAHkcAoLaMACBMYwhwTOYQFHMIUBPIUBtGEGJQRV7gc8DGEOFkYwAQ9BlV9CCKr9slzr5Y3lVQ7arr66CwuYwxQOIVjuoCacV/HSgBnsQg2e/ZMMHaBD3CHBDfgWBG7DKTyHO7AJC/gKgB9UYdiqUngAfejCHPqwWX2jgVO4BZchhHp1Z8fQg2NoQAKPYVGtSwzLe94HC21oAVCHNtRAYAVOoFVt2BgGVQ4eVhtnCGuwCysgMKmWbAxlFaHr0Ayq5a9VwR/BPpxBA1owhV30DHkHHiAZeoKsVVfpQgdmcAIx1Kp4WauSVwSvYRv6cKPa88+qsz+GneqrBQTa1eLmcAyb1S83YQuaFSLZgjfVYbxM/5v/5HA4hm4VMgIJrMMUDqD8J7dxCoBACWewXj3F8mBZgTroMucN4QjacA1GkIOBE3AUn7F4RVDDPMAYSDBnoLAOMwCuQghj2ID7MIEIeqCQgcIGTKqzE8ihBvNqiwHDKssuj9FNOAWFDnhYQAA3wVdJJ4Vj6EABQ8hgt0rb2wA8hg/BwBlswSlsQgm9KsensANDKKALR7AJLXBgoAE9MDCA5hJxfAUzOIcDEOjD2gXM8QWjB7gUAlxG/hqdoXvoCbwFsyrIl0BrGy7DShU+RfXS1qEGh9CAkyq/Dqrz9QD61edHMAcDLXgKEYRwBQbw91UuXy73crE+AQdJtZumMIUOnFZn5csK+61XJ2YOC1hArcpxS3AQwQbUoFGdEo3lMR9CE7bgHE5gDxaQQQc6hD9gfZ2whu9Dg2AHswqXIIYMIjiBAfwIFgAE8ArOYQVCaMAhrECvgh5zaMA5jKALUxhXV+sDUMImTCo0vwUOnkAJQ9iGF7ACswpSA6vQgQxW4U0FU8+ryxbVGi1/RhDBCFbguMoqDTiqqghgAo/gKlxZHurrcAgbADysXq+grzDfJXHM/o7xl9Tv0vkRxTPMCPsDeAGuCoGfoefIPejACig8gxJCaMMEDmEGTWjAfnXcapU7l1jmsIKCXdiHd2AB+1DA62qlXJX4M7gJC3gDt8FV4LuEDkxhBhuwDRkcwCa0KzjWrpDnO3AKr2EFJnAT6hUWW1vur6C64imcQRudIsA2+hg/hL+DjPk++1/SHpGfkx3TuU7NY3KkDl3kFhygObLceufgYBssvIbyIqb0JSLQgKA6rY/hMpxWEHaKKnqE2YbT6jx6BDlaR7roI2QJ4QJ4BEOo/5Ojug0W1mAGCyjhHUggrzbmEgQ8g23oVOs1gs2qLlmWeEtcugSQc3ORMvXJRS3j9ih+i3uCXMensAqGZJVLv0f7Ki//lkWfYoweoYo/R5cH8O9gbsMzeArHsAEWalBDFxX2bcMM/QJ9hFqYoXtwAucQwi7+BUyQFvpzdInIH8AZDJDlNld4XSGSJbBeA4Fv4Bs4gTdVAbCADXgMn4GDLqTwJQyhCw6KquIDNiD4J4H2NTyptpgGUOJ/BYJ42MeUuAX+KdYQXMMPYIKfY9o0rnJ5AHW0hjZQQUpYoLtgKH9N8CEi6DmUyCasoM/AVmjgyUVm1QJ9gP3n8LBKGQ59hTgkQhX3ENNGsgr1xxeRIhF6gn6JeR9uwCa8QCdICw5hCgF8AJegAwPYraqc5ZFaq1DyZaBC4XvQh7eqGjuGFTiDGOpQC0DRIVJHH4OHkMJS7DP4lMxjJpwXHD1kmKutyb0OkzNaTepfs/4WtRVkj/A1KKUSGPQVsgYeDqGLxLBxUcT5HDNHdpAcneF/hrlZFZw12AKF99F/QBJkDzarcqSEfViHTaSN1CsAcY4+qVa/B6vQg3OYQRv2YQuew8uq5N6BqAKKKRzACVwDqarZFPZA4B7EsAd5AHPMNXhO/ozZU0zA/iMe7+uTGc6zJu7natrIZXQ0074z74e4gNNjmpvUN8iXFIwlfgsSWIFmBZEmcB9GsAMJksNreB828Pu4LwkTZO2iapMIP0UyZB1OYQMuoS/QMdKDElmDIbyCt2ANnkMIEQyhDZdhDsOq4lveVQM2wcNTOIcu9GADXkACYbW4h/CrqnIO4Qj2YXNZgQdwih5fQIxiQLCGS/SbCSE6xX+umkED/w3lGzTNwq/EvJfKtqN3xtr3Of81UcLGH+L78Bl+SrCGn2PeRZZV5ZJj2kMuQwvGUMfNKfYIl/BsWUAcQ45+hjSR34VLcAolOkGWlcQBOocx0oAdEPQfkBAt4BBMVccua9112IAVGMEB5NABhb0KCjUhgQFMKpTwHFpwpSokl6ViEFQ1To3oCvU3zI6w53I9JMb/beHeYN+uYLDHn6pOQCOmnnzGwX8lt8RtiiNMg6gJJerRHAZojqyCRR+TPmL0KZ0/ItlBz7ALeBtZQ2Pcb/BzbAPThj7eY1bwv0QGVXXeQBQ9wz3BbsNjmMBlBPQcdcgl9DUI5MgOBHAAa/AankK9StsO9iCo6I5ZhTxuV8jWVgjAXKwJyXIH9THXKIY8+Zzd1zoQfaok4k/wUxib8kSMOoyUkzDMC4xno01/xOCYqx9R79B/QO89Fo+IP8IZzAocowVyDz2BPukLho9o/Ag1kCMQ3sC/Qm6DwR9ifw9i3KfYNTQl/5T4XyEh8vkFJSghsgJ1tI8+ghV0gakjOf4JmmJ2YI6+QUJYgZcXWBeBVehWiH8FDqvyNYO3K/IAOK0YhQI6sLpM0p7FPuWnBC2OXuqnafk17hAMdp38tObeGNTYuAjWHF7dHubbwmwhqaMlHD4jmVDknHxBssLW77N4TO1j/B66QFLEoC3a/4L6jwjfQcbQoPiC8gXxVcwNgvewx9BDAuQYXSAlwSVoX1Ca8h4com8wLTDoAvXoU4oB0V10CnXMGrIBt8ChXyERzMDClSoJNuGbqspJIII7UEJSIewejKFfsVQh9GHLwDbRPYIeusAn7gT3GonwqcmfW1er+SJSa4vzKH2elGmyeNPKfib625xDZd8zzBgcg2E2QqD/fyFTZM7iGzRG7AUZblcIPGLAkP6K9CWH/4nyAP8IfYJ+iSxwv4EFegAv8APS/xN9hblZcaZX8UP8FGkjbewVwmuYjyDEXoEE//iiZpa/RAtwVTYx8Dk8hXXYhz24BJswg2PIYIL+I4RwFSZVev4CvoCRgRHRNervE3SZi1kVu4XOKd/YfC/OD6JwJRN10WoWX0+1HmqJtKERsRJSE5oz8gluQWuTzg/JIH4fEeL7BG/De9CFCGr4Mf4zskdMH+CVuIetk35O9hM0Qg/wD5Ar2HtwFRxS4HchgTPIkBkSo0f4c/wAp5gEmRH8GQIa4ab4h+iXECLLw+EqNKFVMSEGNuAGjOEIYrgN67CABI6gBncqtmgOa3BmLuogs0kZcr1m/mBLVqQ8EDwS01g/M+TxzkJT/JBIJs0/nSX/k5FuwZUWtxq0Y6I2jVW6l5ExvXfRCekXBHcqiv42mqFvCLYwTeYHvP6c4VeEbdLXnP+U4hw/R0vM25gY/wLmhPeIP0IC9An6K4ghhhw3xu1iupQvUYs+QR+BRQ/QtCIhH8A9KOAhHMAQFjCDFUjQZ5BfAPQLcm4f+QhieA0j9LdVIb0BxwH6CWRIQj7h8g1ef62q3kf5rO7DKGourM2Gjy4Vvu5nUovOo/MTfalE8DyTnYKtJqVnXpB4pm8IVwjrlEdoH7roF4jF/AgewwZk5L9hkOGPaa/StlhhcU4wwu0TvI9OkQ0Q9Aj5XcwCfYlcR8+QAHOP+CY+RYTwA0wCQ1SQLewZwR2oo3voHMmrvVOAQwfIkoTag6fwx/AxvIAtSC/YIv8ZZhVVdI68By1I0dMAFtDCP6V4TnHuz7Psi4i6LUYNMfhFXmbN1HfDXjadrue20TXnfq8071imM1Z6RC2yc0bHrF7Bj1GBq0S3URCP9qGBXLmgB/Ur9IQGaIZ7g7xDso5E+F2ibSxQIj+omhBvoI78CUzgH+H7cAOOMV04w3JBsMtLOERuwk30GRLDFkxgBx5WfHNShdI1pFO1PzvQgBUo4SGcog5GiMH9FFnDrOJfBMhf4P6G7AVxi8m+vlB/ipsbL0HgMp2oCV23ueuzoN44KedR/m0Y/Rtv7iaQE0dkM5pb+Am2SVSj+Yf4bzAxmiIFZhkajy6gl3TILd6wusl8ARskMbqAAtOm+BrpYMH8CVLi/hGpYYAQuQ+vYR0M9GFe0bgj/AvkHWQbDpAlObeCPkGuVsG1DsOKVg7hBVj4BH4Ip/CPYNEpchm5cvFW9OyClrU7wUVP2XZJAvKn5kbdbs2spDoZF+cJSNSY2KuaPwltmBe27saBtEre7fD8hMMzOhGasX4HY6FLeAUVxKIzpANNtI9/hP3hRRfQrBG0mSuLhOkXlH2SLaIWvkX+GvaILNEM/RYccgc9RIKqMfszUDQERTxsoQ9wpwRt6EIMQ1hHPX4XexnWq8bskrqNqobquOqbKwp6intN8F1YhSF6gr2KfAceL5H0MTZmMmf0NftDf1wUh5EkLp/Xi1niQxMWc+0bGxc4ibay8F0nufJ6SDthOKcu1FrUPmT6Ga176DEUAGKhgX+NjhCpmlNzOh2KLqUiI0xJ/SoSYRpITO276DHmCiisYXfgLv4cJkhWke3AIXqGH2JX0RZm+Y4fQq9apqeIrbrBBp5VHYHlPQyhhC68Qk+RJn6EuYYssWICJdKEU+jBdgBX0T4nX/P0oX5W+E88rlaWdbwmjbGmOhus5+d1sYSNNOzPgtGg/JwgXsjdhM11ZkOCMePPQLAR+UPyI8Im8ceYa8gQacIULZFDyk8YPuLbF1xu0j9j8w5ugpYEbWY/o/0v0WUH4Rx/jLkLu3CIvFN1H6+BIAvkCP0JfIbcxn2BXEIuo48uiJ6LDH0ZhhfspXwHfEXCLVcqqKqKTcQgy+sn8BaiUENfIG9Dy8BnMCFYpxWw1tUCMd74IlkbJ72xjYrc11O6ouV4sjUZbeW7MSmIMFpClZhZSRAihsUB2iZPKce4XfxjZIHcRt5HStjB3qSskzawq5RtdMH4MeUQd46f4F8igrRhihjYg2UqKat+bx/9Ar6taq4bSE74HiaECBXUInW4XZEVSzHFFhTwZYWblwR+B9aRD9ES/1vwlWhihh5BgdxfNuWDi8DrXsN/K51GuL5i3n6mzzI/xU0suU3yURKNyBAhDsfiC0LoeZolZwuSks471DcZPadMyB9jhPht8BS/Jvo92EOuwDYEyAZlTrLNbIprEe8wPaH+PuUAN6c8IbyLuYTuY95GXyLtSpXioAZ99JsL6YDbx/4p+hxpQob7W4pDkg8uqH7ZhhjO8Q+QD5AItcgG7MMMrkEGZzBEv8JuIzUYXVCu5VOCGJmiA+RJAB8hM8yn9Icc9qVUcaZ4pRh1WaSRDZKC1Dtv42hsfC51kQb0IzY9rwuuOJp1RIhi4jXckGJC3sSGeENUQAQDsl+xOCIO9fWuPnotly27uaz/jBJWXjPeI97k7NfUzum8TTEgCLEF1NAD5D2YX2gNNEPaSBf/DP0PiMfcQy6jjzEN5FrVMtm4YPulBX2oIa7qoCzT87K9I4hHWpX+wsL3MI/h0rJruOzSzMleM3umDwp9mJLiTkw2asS9GXNns0wiV0octbJ8UPcaIhkeCJg41pVmROcy54/RFAzddzETglUExKBDALnG4BNe/Ee23mI+4SDTvqir2cGcqMHwDdNTVjbpP2ClJCrRGcULmj/AP4MQSS+UK/q36AR1yB2CD2CITtBztI9ZI+ziHmDeQnYuOtd6hqygpzCv+KAluzpBnyD/4qLy8vuY34EBDOAD7G14B3LkEG4EUJK/oShlpUUnLR/h60GWtXRg0tNW2Ei9S1wWlsSkGpCX0ki2DeGcmcFClHD2GTYimxK3CdbxKeUJ8VsE2xX6yGjd5OafUl+Vm/v6YiwbASfKZo3hiIUjTOCM1ZvEEX5KvIO5i06RBPlO1XfpQRN7GXkLIswWXL1oq5efIKAh7iXSwb/A3oYEWUH3kS4kcBtWq1Zir5KvbC8LS/i66ug+hBSG6DP8Q6wL4CuSDrUG1+scB+WbssyNH5uJbqo34lxYzH1pWShWbFLYWc7AqSD/4w6BZXCMDNm5AY72HdwpOsdsYnaQGAzsoEdECb0fE99Q/i15Jm0HTS7dItijvoo1JAka0v0YYsLb+D3ckOCHsA67Fx0xuQon0IYYTtEpch3dxdYvGOXwOyi4Z5gQ+QA9giZsVx1KhQYcwBz5ABL4FpbF9wwa6BRewQJpwWtQ9DhA+5g2xYjP9sv/t9QzyqE1UtQb/ZxGYDNNRUxZawxn5VZpG3ZS0inlMkygNmKtRaeFnxF4iiOSP0Wa2BCToUOki36NHzN9zsEvufLPkZCZUjopMwa7hHXiDfJ9kmtM3uAtFnQICTqvVHIeHlVSwc2K8D5Ez/G/xayiC7TA7uCeIE3CP0A6kEALWXb0V2Fw8fBsomforzHvwDncxD+GAtNE1lFwn2GnyDomh1qAFuTPGAz8F6UfQEs48+33+hRu8aI3KzajeDpZrJt5qV4Ln9h2pj6XDdh/w+UIW2cDbExRUmTohKiHKaGHevKvCdbxhyz2yUqOfi4TYU1IHZ2MssSkNLr4N2QLOu9jFHsLt48PMGvwCg2QKTqDOTq7aHiaH8I7yFNYIA3kGroBp+gZskC24Bx9htyCHejCKVyDGN5U4sFJlfgv4T9BjuAWWCRFFWL8KXhEAsxH8ICwbj5qBboIsrCcqYYsHrVJXa4tNYCd+c1IpoIrxlH+X8S06+b3Y7aUwxn9nLUPaLYJDMUTkj9CAvwutElPccekb/jqG/0kpTniPPdDNRmy7XkzYCXh7BOo0Vole4NZg68Z/ZZX37D2Np1rmJ8ShYgiNfJXlAtql4gjmFF8SfhXF1oJuQQN7Bj/EvdrtI5pw9lFR4QnEMFVKGAdDjCXqzTUJngfXTZ778KA4D5yE57BFfy3AZyQ3OBaxOrPjXnof+mjy3M3s86F7eaByd08WwlMGssksX0fh8kHqe0idxtMU4IWWw3KUwb71BsEIZMT/CuSK7hzXIEfczpiMNRfL9xDa+4ilyLOc2krkSNeodEkn1H/Do0/4+z/oLmGe47PORPaq0yeUIxYu0V8BbV4S/33CVfQ58gm9i1ku9ogv7io1P0YCSHGXIVNiOAFKvAIWcAxXEWW5dgKXIMB3EQ6VYsxRG6ib5CrkGO6AbpP/pLRU+boXPOfLLTA9srGzaEfGpn7WCap74RmYmo+vObjv+iwdyrhiEnOidK8zfyQ2Smv5vqm756K3y+De18QKt7KFdGnpU7wz5CeA1hfN1dPMY66YbVJOefy+2QnLP4r8XexXYL3CVNGD8mPWJyRxORj8ickN6BF/C46wb3CWuyHlYSlXkkTdwi+C13kCiz72h1YRV6jAexBEzIABA7AwkElFWxf6Or0q0qpuI3UAtwZg8/5yW/Kv9Pyt97PbNkPGu+l5ZnMTzsL1+t0D9w8Lqm7om6mJvvfFo3vmuDtjEj02wJ5IGtKumCaur/36T8G3kbRae5eiL2iwXVX7osfmvI8DJqZ3fXB0Ym56S8QydUxHk4f0+jAZYqvyDsYy+HPyl/MzPQL8xb0HekeRZdNTxSSPICQ9DFJQHwZ/QXSrBRWGbSRDy962USVPqCADnIbJpVYK4FGpfNuVMKiAEboEH+C+QiW7TYf4NcxsfY7enROiUQ+upHnD22xH1jygMyX1vpiLutaGnnhQzNNng7dbTF3Aj1E3lZSiyit0v5VO3Rp8Vx1LIopzgKzlpWH4s9NnjWYlzpzwQdebnVYFXZHZOAy0pKtHxBfof8KvkaPOTwsvsxCFVNXmo6xY6VkP2Xnfc7/M9ZilPAQ9wgdYzeQdRijL2EF2a7kcSsX7UYO4V6lsV+qPnYq3etLWEXPoI/YCzmpXEI/hx04QExAENL5SH53P2wM7bdOnXd7Mv4PnUXeCzQjkqxsF65eS/rzxYpigjB3i8C9Kcya8y8L0zKyIv4lOkJ6qU7V74q9JeamcYdGGkhiJPFhuDANwvtIYHRQMPechpIpHkQRQz5k3mc8Q0fMjRtY+8rpLSNjh/XcbjFJOdmlaehuE14CwZ+D4KeYOjIAi/sl9jZyCQpYgyvQqsJwD65XleoE8qqyE1yOXMI2YAf5HvISfYl+BRHycYCEmBpvfUhsTfySsRavjPgyk5bTKOlNbKOYv+j53DbDUxeGpizFguIPvS7Qfa+rAS1MV1Ald4SBFqJezCXwogOlVMRJrOaSYS3idI5At0ecMGzRVbIRg1OenmBbNJu83ZHVR+a6ii1pdlldsH/KlasszilCzBUkxDQxEd7BFA2QTeQD7AqypIR2qwZhcVF/6RGyVenllxK/3YqHHSBLffIJrMMHyBhWl7yHQdYpcs6+IA4I6+6h6uM8aJYJI1Tzs1q+XweZu1VQawpVG94v7TuhrAdmE9lGX5ZCiSBvYZpeAo+F1EhLJFHbcqaFz6PyOHYPvX+y8EVIr62jlOND/bqvv+nz6gmf/Lz864H+9rU+esSjfTdLNBRVNDHUwDU5EtSSOU6ecfg184f4nNkDygmS4PfRGdKoJItLrt3CI/QLGFbS6hAW1c56C2nA1Yvg8suc/SUsq9QSLZYKswVhnXDD//uvyv86YeGLk8gNTLySFdOWW5SBSxNGLggLX9OZBJq6URDfc5ypfwOnSAxW9Ago8sM4H8Qmc/Yq5W8CWTXFceBTSYu2TcqgX/phbp3DLPxrlS3rv5zgMWtzPdP8UxM3vYw8++fpyWXz0FmzkCiBAQvP8BV3QqaORp/sNdwCmO7j5nRCilOiDNtAF8h9SOEQ7sM1pIQJ8mNoQx32YLfSId9GAswpuhRxbaAvkHMkQpctVg3gCAONqzp4UH7jpSc2KfOw4de6jWQog4VOKUxjbf15Om1N5luRnUi/0BcQhvYjQ1elJtTQ2PmvS53bMo+jVlo8FYkV403DuzQqbN15DfYWyWphup5Trydwhi6WqdODOB+TpepVtk2R1IuT1HdmcnZk7qlc8dyMqcUcTlmr0xVqTeZ91v4CUbSgmOB/S/0P0DH+N1DHXoK0csoMYQvCyvMyhxYcwRjayO8iS7HDLaQPu+gEuQc1ODKwRbbH5FuzMgku407AEF5z5bN5wxzU2sMyiB02qGdBkiVmnHSnbmj0AGmiY1BhJdRnzn9Z+iO8WmlZnXsTqxb4BTr36kRz8Smo2EuYd0Xext6CjUja1qyJdO3S1+AHFyYKKV2wUxJA18tNSIVESBdYMML2fZprKIRvEzWRVUyCG6JLEn7Zv55ULqulKHGlOt1sZbpI0E+rzsdGpSjvwqKy88whC+AYB6/OGRWyQYTKvbq8kNremd3R+ZNW4ZOxbtX2RlZzVwZuFkQ7gWaB350jyLWafpv6p6WW6BwmTnwRXPMyKzU08R9HxS9Kf1iGo4UYZ4LCT6FhZe5YEyglUFmBzS0Zntlt9RKryWxXo94iTJzZQm5a2gkmYrFgM+Hm2wTQuETjEvaA8lPCFewKjf8eAqQBl9AR8i4AC8gvWo8Xmrs1aMHehX5YPoYAHlZulS4M0BPkCrAUJBuYM3rt/8ue38efoKEs/l05/vua7Wm2m5SDKAjySNN5trIoeoFkUpPgTmQ/6Jk1pAaiOGM2sRuYLcLVrHFtIOPSz8WuePNWVyWQUAObGuOpGepwVlKqNGNpWTZUZ6q/OfC/zt0J2WemeBpjA1I0SsSKWCgvEbepW+pNps9JD/Ej0mPCLUyPcnwhQhe5MDvKNlwHgQGsIDdhtUreS3X1SgUmN2AAl3HP8I+WagVoQq1yDG4HqCefuAeUX4p6NdeC6XRD1AW9cvayhy+zsp0wqm+N036TUq0t8s8y/DT854H7ByenqdvH7lA+NhJqfhwHrZwcWy8kpfxZn8yR1FLfRZVjH7iFf+TsTcgzamIuobtC2SCfycK5gQlue32uzNS/WfD9kMTrwalsK62AuM5iTk0oLUkdf4ZsYSP8Kcwxl5AlMXQKB5UxJ4Ib0K2kUzP0c7iL3IHncBVa+Oe4Q4IN/ANIIL2QLouDScD0Fxw9c2e+PLOSkH6alK4W6zB9Wku2Rv3+jcl4qx4MnESLohcm86CVkSMCYyd1dZ/jzsVuo15FiG+kkqtsQEtNC7NGuWf9a9HAOA2t5q6M3bgwp4X2vb0KDWEbueJMRCKu/MbZFaURJd2xjb2sK71ADjMCy/od6h20ZOVdXEZ0A7/A9OANWsc2K4vOUiu1CzcqE+x/E/ZnkCJbVRNxGzz+Ef4UexuzCQ5V3NfYVfQQ2YKjAJ8wGpsEs6rFrOEWgQnLtOiE+UJSmS967fBo7rvTo57XIFismqEPa2lcP6dpy2MnTQ3qKmsSt5Qe7hvFkT8Jyi+p/WlprhOcumLPqRpR9RL5UmRVWBP3Um0Bq5G0Y7qhNFvBrdJ+7KU24U6n1p+ZWy3iGQJ3W1y5iwXj6ewQrlCP8COC23AGAbIKK0hcCeuSyte7lAh1oaxMxksN9/XK/jqAFDKMvTA+ihL8EFpIEww6Dmj/Lu1v/NkXZl2xotNoPuvFjJyGB0d3z9i5kZx0o4PXs/cVZvTGZ2t1M66PZvUgK94keu51IdGilKIwl8gfBrbtdCHBO2hf9Ez9HhQ+dFOpm6Q7jpI0uOmlqcEd6MCld+gZ5n1W2kwGMk9JQlwCDYaHbG0jIfkrYks6RmuYBm6BUSTFT4neQTvoCSZG3sI/QF4hOVyvDDIrEMAudOA6KDyEG6CQwCliCP4KBCy8QA+R+5DBZXiA5AH+FBOH71PuivsSY4rIztQFM11JaVvK3eyDnpxGLBIzzX3dUhhfFqcB47mtO3emPozKgQ97aGRtx4mqW1h9gVz1YcObHQ2nZdKfSKCc++hfWfN2TQsnoeH9VfyAcU6nDjPMjJZDlGen5a+93SiC1TFFzrsRu5+T5TSazFLWarTvkPQo+nRWcZ6ogVj0BfocDTA3kaUCaqkYew5vwWtIoQvLEBvDDijyB1W3I4R7uOfYElGw8CP8XwfMPiU8p2aKV8as+vw0Ct18yqbgI1KPRTXVZiiLuh1ZXyYMLaUu8C8wkgcf4g7K6A9VFzBybIp7hoTqRqF0HHNHTnhf3S/mbmyS+6m9UdOhyFpNRxFbP2T/70lHXHmHfEgnQCc032XyisUBLUuZEyutTc4nxAFFTqGElwkN6Qm2g5shYHZggX+NuVrJo1sQAnBcmVMOYAavK4/IFC3wv8V+B53jX2DqyBamh6ygu0gKl5GrAeFVFk/Kr1VPfNFsnPlbAdmY1Ujyoa61OQtwjkCs0Wth/GIWm2loZtGNzFyDT1Qg+p7aP4/9t/Aic3sqIdaU9GBS+hNMG5xG13LpSfCWlVUkTulE4nK0wNa5+2P8GfVNepdYnRNfx5dm58C8m/BWg/Mz4ibNEdbQuUGyQvc9WKBNNMXEhL+HgLYwC2QdfVXVXKuQwn2oVTLNEN5UFrsFkuJOMeeQoGfwDsww1/+bABgKZCdgccbRK6mr04ix4pkEa87bTvh6lrfrOiqJLYUpnRvZIMitltGVPNzMVQhuY+4jHv/TYmmbNpeRCP9GTM2bumofuzQ1KfaWcrklN3pEh+iCVaU4ptMl7hBt4VNKR/MeMqC1CP8yYksI4N07dFap17E9en+IOye8j44wTYpX2PjCQSe+2hpaiRJzyCsX1NGFLP3CQDqEDWhgb4MiTewVmKEJ0oFDJEIHyAI2DEHA1ToxpqFivQ1KDSXyRamN1CR9LjXo59QWdOannUm+Pi02F4OeKVRnF/5gdZQ/9+6Zd88ofmPcvhBRHpjiKQRQQISsGbliSRekSmTpdskDZIXed5g/w6ygBj+k+JZySpCoqzGbIo58ju0wn5LPyHfJx/BDqKNTghsouEf4RzCFLtyt3J1Lyf2VylyYVl7LpUuhc1HWmxhJ4Bgdoi3ooK9wr9Ap+i36CP2Vof5DTEsnxDu5b0SaEyyyGsNZvmqcpjT2eSejNqXtEYNTCBo5MRjxZzCV8lOTPwnKB5J/KWXfurHxx2LaPryJDtESEutPjX+ljDL6uxQl5yPKnPQVEoNHx9g10ilqyQZEa0Rr1BI2rxF1wNDYIYwqEcg/wBHaRC4ja5hLkMD1i1kBYpGi2jjnlVhzDC1YCkWuVDTQATh0KT4TGCEddAR15Cbyo6VJI8C+z6Xvh/9izLNB8tmse/466qVZvzF1Ww36fS5N6VhmiO+GRyYvG3IY5XM/tuHdhv/PY9+ty7WSX+aaInUNOwU18TNjAq8pfioWpdvzi8LORnShrRihVeNsTGA4/Slxj+lDyga739Ds0PoA12P8C1ZWOH2FQGRp3cDPiLfJTyh+SXQX9vAZeoBPoUDq6AzzAXwMr6oRAduQwrjyrRxctFVpQQ73YQgvYBtzB30FhvwYf0LikR3wmO8HyA6dm+bPfq1+VHs8iu5Ooj/w6X+ahuN8MezUi8mK7Htjvbc2KIwtonoWbJb2nqEnsir6eiYx0hCzojqneGnVBmpNUC9MJD4Tf6L+izOfi15BUpgbfIPaDewZNDh/jh/QiMgMh33mZySPmXj392o/nMh3E5KAFwfs5Lgpk3MM9N5C5sgYW6ccU4wI1jB7iMAQPYAMCaABa9X4hkO4BBP8LnqM/d7FwAT/OaLIpYpUu0b4FvkJ/gBzhlyGToAeoK8pp6wYs+lx3u0SXi2aRyf1W6NueOy+Vj+WXJtuHjUuD/wisDcL80ebZLY8nZuFWlsGt9RPDaJqTHS3LPJIF8adeC0k+6U1a7gi5OeZ3dBAMY1c5ZQXY3Fj/XpEGMhbQqDl/1foQMwVZ+rMf1uPAmItuKGSHnE6pq7YPVzCfUNzQLFgeobmrNzC1Jh8S9AgmuL6RP8M+xZQOZfncAglXEW/wr/EblY9jBdV1ZpfOHUlJdzCbqEn+CPsPEC/IbrMrCanw2W5l/5/xu5ofhIHNd/80Xi6m0hBtJiWNpE8z4bt8Eke/OzUNHCjyJ+pNMp8N8jytm06u1osdgM/Fu9CCm9tLtb6gSlsvbV25CaiuUY34fS1/8LbtjBRmiV0CFL/2rk9bIz9Q8o4kQPCXinGy59s8uhUzx1v0FEu+1/Jx6sMBySGdo3DXxA/YvMH6AJ/DhbZhxXYgZfVJIXwYkaH/XPsF5VAb4LUMQG8QSx8AA5TwzShiWyiZ7AXkH+D3WD1MtuHyzEzds1TEuwU5Unsd3MRgkte98paZ2gvazEoyjdS/pci+B5uUg/CLLjD4k2sqZ3Nu8aUxnibFATq80CculFso8LECoID57GeXiRbKaJy11B4bmxhfPDjQ36DFFM6EsWz8J1Qrlq53GJzh7O+DL3ea8hRTiukrFOe0t6i2SZ1tG/Q+DHuGcFSxNhCp8gIEjiuDPHb1WyfoBrsM0IC5GbVp5fK5nsd/RI+QK6hvw3AICWX36d7xXz7pa7ty24mYsR5G6W+JGhnEhK8X5rr1lzS8LuL8m8L8926vGNS3wvzeZKdKjbXuom80yRIJuFa5s4DH5rS1wObBnFWJtaueSk9S0587mRpGZkp6xH5CWLNH7Wid51Kwkaj/j/syQdGVLn/Z8QnvPshLpOVP2P2hNoN4i5+gI2gQBxBD/sWdgudIdv4T6GFZJWBfLUaDPI1tOA2HMITuI55GwpoVZ7NGIoLy7p+hXwHuR4Q/wXuVxQDap6rsRQS/RCfNvzRnLErD8R+B3E6+/dJcFqEmy4/tTqPojUv1zt53Mlfh9HPx4tsJW+2671hkp+nRw0zz7y1ElG/PvRTkXEZpRMWPvrLpeTQyaZhFtExxAGrMSs3sQaXsikSNonWzJ8PWGmTNGl5ev8L/inuU8Lfo30fujCDCP8GWcGfoPOLulSAq5gTyGAE9Wr6h1YDEzpwjpZwjAT45+gp9v7FhBz/c1jFdJAW2oc+5AEakR+BY/SY0YE+SHWOvpzkD63Ug+B26b6W8H2CK14KfD3KjuqBzWhEmMQEzjJ3EmlpEzPiIC/KMF5Pa7cL/3jsNLJFbruqC6Qh0feQupFbCd2AzQ6jjE2DCSkNrbdJVlGHOKL3cfvs7NH9M8IQ3UUfYCLM78M5qsgQBDYQi3SwIbqkuOrwAwjRHdw/Yj9EapWy8TP8GfYq5S66T/AHSAx7SBfdRx3SgTEquG+xtzAbyFUo0H6ApBR9AovtMV/X43+UK9gadkD5WsqHNn8Z0vZqxb0x8U5Zvz6WdbE36/rmPJrl4aW5CV0zOZmfrCjWShb4hZ44r7acRK6ITJGG686uFDSWmsxCUHoZxQLpMUlZX6XIsQMsBBv4A4wj6RFtUAwoTwhfY28ia9Vsq2P80nXgYY7GyFK8shSQlegj3GvsdTipeMVNdBlBE6SN7KAPkUuIYnr459g2vId5jh8iaxBfjMfwewHSJ2gy/RZRklyu96Q+9OeqQyeR5nuJN2b6Vc2Yon5r7M9UQmGspIHcc9HGPGiVeirM87yoNRp9l4XlwlmZLMYbpumLSRz4iMlMKMMmqsIYak7qZ4QN9s6YOjoN9DHBLeYD4gm1TaL3kIdwRvkE00WaEKK7yB10F91FNpAupPgj3GvMCvb70IInUGASon+GbMLSbraGLOcV7BDE6BjtIz1ooru4CX6AGSFtCLA3EYM/xfRhA/svA1DCa9RHSB3dlb+4w+kzKdfs5qOg6fG565ti1IhvZVgvSLFrwttOF6GEC2kKr4v8uC5q1ct80StMLSlHLk/UaTkKC2qegFQMhe7l5mpbR6kaZCdk17O+ihwwH1IHCan/gLCH34VN4jYSEm8xe4j5hvAAExAUEKJzJIOb+D38GeYmnKL7cIjEcAkWSAQd+DGcQxOOsX9cDfibw1JPJrg57hi7TvmU8BCaGNACUdSDIL2A8ltsl3AVH1MvCUf6pk53EnyM+wScj677qH4mgdeS4D3l70u7Dr95o9GKK2JxeamJXS0Xw140n3us4LOyJdY1gsNQZnneysp2Pm8k0zf2ZI7PGQmLkK5nNCATahl6TvQ1vCLuMt1lZUC6j4DLmR9S38GnBO+gjYvEsfgMs4ef4AYEPVyf4IxoG7kFKXqMXIYS3qDfID+oZjI9gBjZgScwx72kfEJ4Hc1gBp9dKGQFzHtojv8MmwVkJ4QB4QbjZ/zyP2uq+f8+ZehVETANby+hC7CYNjLDJ6HteCKnvxyWr7eKfndcbtV0mkstZBaQJvbcNLy3SbRS6nga29n45NK8WF18eRZszqSp/qU1dyyXLPslrRq9DTKH3CCcsNjHZ+gMC0GDYJWVkNp38aeQwSHpK+LvQYLmEBJ0CBqYdUyP4pBggA3wIyTE7FSz1g4qoqOOvkHWYRWmSI/gCqaN38dcgnuwwH+OPyC8gVyGCG0ERG/jd5lPmZ8zStnLCJCrGHDPCD/CnUjxLeEtLU5i/4TZi5596Xp/fiotn2atSbY+p20W+0GZCagxNimCMAvupKbm/TFuLA17ZLXQoU9/G8RvO/eqNGul+XiDZkxtj3SV5m1GJ9Qh6NBqE3eYHpJ/y9oP0AXzz4mvUvYpj8n6hJvU/xQ/Qo8op5gO4e/gv2D6JdEejT9Gx+gpZhWayHfgGFYuTAhLZbLOkA3MBiaDFUyAe448QuqYFroc6HCACZA8wNYxq0xe0P+KKxGvMnEwxtyFArkSG2fsxkIjynNbnEXJ9rzMIzrIqmQ0EB+QB2UWe9MMT6ym0bUi2MTe9G7Pmg0XvK18W/rDWdjM/BG6hi5HAAULFnPmyuCAywvSnGZEHONTomuceZJntG8wPyT2JFdYPKGcUxZkZ+g3aIooImgJc8wmrQ+Rt3ELzH2kVjWRC7h8oVTkNpygD/F9TBf3GdLABpBiLpN9SnQdaZOn2GOkDjl6GGCu4afUr9F8QVSTj4PApe5nCx2C4r/KzTrhe2CwO3M3nLuvTfI2wfdFgyBpzhvaz9N6U48KW29/99y/8ZJ5YsxNY96rMZhJXc2dMnFTCaX4+8IPif51ZLY8s5B4RhygBpfSeZumxwjFEcU+7pR4lcVTojb2Jub7mJfMnjM6YHGIMQRtVu5BhEzx/xl1GIvtUTyCV4S/c+EO8gtkhj/A7RGtwQI/QhUmiAF3MV9SRzBHRxd+Id3DZUgT82EAHcoBfkTUYvUy3WPTeYXPpCvMvQ6QFvRCCbyeu+DOZfcPx/ZGyQ5SN42NvvVpUKRRMo9qWXSzKIYEt5AeOkWCmWwooQiYVWVlVb4Y+aOUzGjfMetLItwN6SaYOsUr5pZ4jXqX4QkvpxQR8xFRjXaKpkRXCJ5TzzErFEOyPskp2Qlhk9ZN0kPq19GvCN7HPaT8gmABjvwzgk10RnFG8CnmDlJHEiiwH6CvYAYhskZ0G+lTPMIskIjsFWabOApQj42JrxEPMG0WT9m+bf7NTcZHzIZSb6MBSYPzc3lxSHcS/NjTFuoxN/+ofvNLuzGRr1y0Ubqpw6tdx2wbSfwF890TbnbExfhT/CC44/LXuE9S08NsoQuVlwVvzwlDogZ2weScZJWFz//t0H6UGHMq63B3zPQztlbYn+inU7k3IE+ZZbBPT1iv0znAj+gtWO/gHhIYAo8eIxtoDB2CW/ANFDBDIvwB8rv4V8iA/AG2h70H19HPCO7jxkhIdBtZh5MAWccL5ZB4FTHUrxCEdNZptQhuUb7CDWl9RHTK7P8mTtlokcNYaX0nevuhoEk5M4I0kFXMAvODGvszudfV4zmrwnqDgxNGnu1Qbvrwx4Hcbxg/0xS5ErHToxhxOmV6RhOGyvaIXpLvxeH5md3y5gqiR5IYzqd4474pjYnNlup5yEkmdxM9msnKmFrINz/n8qdIyfoVbvwpxVPsGvkBmlFLMYrUyf8BexVfo/wP2DqmyfyEoEbtGPccM0QiiufINnIDPEyWw00UdYQ3GP+aYsJ0TPMmySWS75M6zl9Rn1Ibcfs+UiPtU9tgcACluTVmiqkhNcwa5joawSylFXOrI27ORp1GQjdk4zqNVP6wYf84ZHSuP51KT+jBkeC9vnZMFUPxW+zd1NxO5ydbsYzi4Uz2sCORFtL2euizrwL7fBr/JRqGfh+zFYuUeKEwRDvkZ9QtkbB4zvyE+A5hgAjlAfkhcQ2XYwS/wKVENyjeMH3I/Kdsf4wJCK7i55QTzCn5PvYS9RsB5U8xJVGX+QtEiFeJL+G6+FPclORDmscEq8Rn1HbIBjS3qF1j4z3MbalbLa2WXqaKgxlyLZB6QF6SjUmE8xH1nFCIx0ymlEOu3tKDsPwHZ9/CSOk+ndPolHmr/OW5P5X56Yr91LXv9UfnG3Feax0fmsTFi8xuOww6FzcIo/ede1RKMyOBwUx6Sma5HVEuWF3HGLzj+BFRk+iERYoR8hSzgsmxMeKJttArOEdxTO9Dan2S72BC5B5+Fz1k+oIyRw7RgwB3iomwXWyf2gb2KtHbZF+Ax4C9TrhNcUDYxST0H1HbZv6K3h9RPCdIOUCMUkdHKMjAcQ3elLwYgtIxlI5hSXBGEKDCaSYrl83GLgv8N/h9KEazl9H50/uJTmf0yjdxNPtECh/0yqhX2DUNP0Sa4l+rrGpwlNv7dT2BeW434G5AliMwd0Q5pUVCipJGi2SN2jU8JFvM9gCICK6AQ7rIGtrH9pCA7vswx3wPPcAkmA5Rh8U/EMZkkwDWQfBjLHhzwW/7HBOz9BAwxbSQFK0Tr1C7TPqa4ackmwRtWqLjsY6gjfl+R5/MQNmAjTplAQGNdeZnnM3oGvrK8WuuDc13hZoQ1KQ/88/w7SDTZsseqa7WklF8r4y/nTfCM1srgvexO9BDrhhy4qbI99fNm13/aOlfsRcN+6SJVcIYY+jcpbbF6d+QtJAa0sRNKIbYS9RuwgJdwEt0iAjFKXQpT2i8g5+S/QIc+RSfkR1TawfMv8E44mukJeFt/EPG/wWf4XKmBzSuYISgjfPMn1N7lyLl2TfMHbfedl8X+vXUDZEQAX048w+cOVVuIcMZtzu0a6x/TPlL5hnbO3Ry1BOVsh2xasmK4IfiWxo8Llbarzt3T7OTlebqefh9Hx1nVkt/jr5B1xCDvN8gzczUSXZKK4G59lWfzeVWImuG8YjNVU7HNOuMvqbxApdx9oA8ZXvO7DVBQvqIaBPnCLbQEXbzYvRHeYorAWydoIXPSFKitwlamOsBB7+ktkagPPpPXO3hPfUtTkeMR9x5j+c/IYlYuUZ9G5Nx9I9EMZpAwekz9yyThS/zxJ2LUSc/yZngjzFvkJ6X+VDCIc//Wk8y6cHZG95fZXROv0NYZzZiJioiLTWzvPVubgrPQIOPnfkA/+8sm4EscmKlgw5Vjica19yeWDvRPfw+AHX1rxfhjy0jy4tDWQ+JRjSEMmT7h+R9pm+YHkGT9JT6Vcp9Fq9IblHu0fxXuAy7BWOsB4sumI45+prL9xm+IG5hDwLCGvkQeUkU0rhEHnD2lL2crKT+OSc5rZiypD0nnbB7wDCj1+J8QVq6Y7G9JJ+39MyZoMh+6uy2RiteF8gVdCj0arxC90ufozNnGwtOS9wxQ+igL/B9pEQn4hYSRDhCnVmGlBK7MOAwMOfOP/FSQz9Hjc7/LknuFYy8P0MsxEKq+ocxvqmfn9g/i5CA1Tr9GdEGjW0WC2prmJisREokJbmJxERv4V9hAoIuNkJKdIyWHP6G3zzi4zHFgvqM9kbAtX/N4kuoUW/S+pDynBgutYi6HH1CPqbRQQNmR8wmrAQc5SxySs84cifqnml61ozcpCjqGJe/Dv1sahI1r71mmE5qmmDwp+hCpTWmKKWBJBBazb3fVx1SjgL1xi3C3NcWz2utd8WtRtlewkkYm0WNWfAW5bfQy/NxK2kbpl4X+ILozyOzpjJJ5ZbXHwV0e0QTVOk1MBB3WFmlcYnZCaaNWGyLaAttYyx+D1K0g3TQGeYG/jkr29yekUTYlPoWrXcC7CphG3MdW2IN8xQHl/+A6W/YusmVqwRXWTzi9BNwrG7wzimpIxGOitl0K32aLIKukY446i4W5+1ZXtbrwWjOTIJWZlqqhfW5labo56XpmfC61xK5an1fywMjqSunoXqTFq1hunL+YL3eHvhzkx3UVAIXNpqbMz+gODQ2FhIxq4EEzjRVBXvPgeLhflvmKUmNwBPVWfQxhvkr1GPb1AzTJ0iEzzERksEWchvbwj8ke8ViTmsfhCTmnVsEEWVA8xbWBciQsMfkU4yQrGLPcAvyfRYDrCApg7/n1dcUJccLWhNO0Yky8jrhPL8yZHNe1h1hwrzGLGbeKFdloIFPQzu3WujIkjuvATUrz1zt5lj7M3dqosN89tv2Yr8ZN2bztDMrVjv+ZKHJhJX8ZZKkwzgc5mXdOrMcTCde3TOjx+pPfHhLvWIayG1DVOdkji+p1di4zMGXtLZpr5HUMNu4c0ydWovaO5g15ArkcAs8MkK24XPyY47/hmBOdAPTpLXDYo/mDZLv4PcDZl+S3EUaaE7/b0kusXqDyVeow7Y4/BXFAmvwhoEwcHqMFrjP8QuZHdSmtOfEgmSEhmLsV2a+AyYkxWk0z4RcsbbmiqxmfdF9s1fu9vOy3pj0F66ziHuz0fpY1wZsRmQxZUtehLOxlSxqTe0oi3peYswWkVe5G9qfDIK7Xm437bZnzXKty3TBzm1WLpGeUl9j+3tEQu0OyV18g+wnhFfhEELcGXYFzfCfYRQELbAJjTW2vkPrh5hNwl1okqxRvsGHmJsB2RnymOZVXMD4P2CE1k3KOX5IMSdf0LvC1jpHX/P7O7x8JaTSSKRbFF9q7PM2/YCmI/AYTwSakygUWMHP6QAOKwtVJGHhskAxM9bM0E/c+tht1hgJshIedM3rsgw6shdfSgtHcBmOSttzxKjH3BC5XYvK3NwUpMkVx40unQ5dSNbQGY1VbJf1D0mfErwPa+T/D8MH5KdEDeIVZBNzyOKnZKfYmxAx/ZJkm/SA3vsUx4TblDn+AfM9yjlhFxsHtO6xOED3MCFhE7UQYts0V9EG136H+df4lMMxNaXhdQznTq6r+49BUJRNxgZn8J4wJPUXUD+05OA9IYihFNGwlelYQuZ2VWutmY3Rx7bOIJGxKA17Esos0izqZqaHmXi76tMXTQZFOEtlx7gnmId99wQU89GUgwXzKZ0DVlfpZSB0ruAmzD4lHTEfsfrfEd5CvwKHT6FF0EYWBJuUM0yCWaMYsThAoXOb/Ax7mXJKuEFrE51g1zArAWXK+XNOh6Qx8ybREdePePqKq5skNeIuqx8wf85ak8EEr4ShFiGPimIWL+gIogQedQSQKBKSYVXFUBqLBwzOqGMmglrKYhAHvaxchAaP0SDMTeZCk3oJnbe6GgbfJf+pnX8SZPOWTubFwzSwfvGLBG+KN7a+N5fPctvxsrIgQDYKueVkZUT9DTi6NUxIY5X0NwQ9Vu5S/5OLeTumhXqid4nuwF3Y5soO7hU6wtaQjzF3qbfxZwQ/hENI0SzAO5IOg+fsFdpHrnfwY0rLYkT/NbJBnOBmtG+x+0sS5EpNtlb0V4VO1FKUxBZncAG5wSsmYo5RY5yUutROBmSGUp1YcksuHruXm8DHwcRGhWgZy9Qar2LBMlIRgm4xf5y40pZDyhmmTvkySMcdNRI+TcsTE26K7ahpIc3cXt23vwMNw60aPsLUad6lnBLdww4xl/FfojFaINegBy9BcV8x+wmuJJ/gU9bX0NfIGsZT/gTpIVuYMKDxV9i/46OPufy3svstvRqPT/jR/8x2yO7f8eCQnT6t9+jcYvYFyQ3dfywrffn9brNVXP1fv3Qu0KmaO0H5tYpzUsPnxlh04cyKNy0kUBM5HXlzuSXlwvi5NMV4Z9remb7sl+Z+lD88D++v2z/YqP38ZTAey+8n8U4a/knsioBni+AjY8S2fu9m/ZtXPti21sX5sYm9tAO5d4/xN3LlHW5vUBQ0J7TbtDawG4gj+BPsBzDDh+gpZgfuQ4r7G/Ql+ZzJjOFDZo5swOq7lK8I/xhz82IKkhiE/x9j2TyqQfDPiQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=96x96 at 0x7FEB6D740F98>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "a=Image.open('../input/audio/sheila/' + sheila[9])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name_list = yes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['151bfb79_nohash_1.png',\n",
       " '7096522d_nohash_0.png',\n",
       " '24c9f572_nohash_0.png',\n",
       " 'c1eebc0b_nohash_0.png',\n",
       " '47565088_nohash_0.png',\n",
       " '5e3dde6b_nohash_1.png',\n",
       " '333784b7_nohash_4.png',\n",
       " 'a3fc7884_nohash_0.png',\n",
       " 'e8e960fd_nohash_0.png',\n",
       " 'd430b3cc_nohash_0.png']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle images\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(cat)\n",
    "shuffle(down)\n",
    "shuffle(four)\n",
    "shuffle(house)\n",
    "shuffle(nine)\n",
    "shuffle(on)\n",
    "shuffle(seven)\n",
    "shuffle(stop)\n",
    "shuffle(two)\n",
    "shuffle(yes)\n",
    "shuffle(bed)\n",
    "shuffle(eight)\n",
    "shuffle(go)\n",
    "shuffle(left)\n",
    "shuffle(no)\n",
    "shuffle(one)\n",
    "shuffle(sheila)\n",
    "shuffle(three)\n",
    "shuffle(up)\n",
    "shuffle(zero)\n",
    "shuffle(bird)\n",
    "shuffle(dog)\n",
    "shuffle(five)\n",
    "shuffle(happy)\n",
    "shuffle(marvin)\n",
    "shuffle(off)\n",
    "shuffle(right)\n",
    "shuffle(six)\n",
    "shuffle(tree)\n",
    "shuffle(wow)\n",
    "shuffle(silence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Yes Spectrogram Images to Pixels\n",
    "\n",
    "data = np.empty((4050,96,96,3), dtype=np.float32)\n",
    "\n",
    "# top 10\n",
    "\n",
    "index = 0\n",
    "image_name_list = yes\n",
    "for image_name in image_name_list[:200]:\n",
    "    imageA = Image.open('../input/audio/yes/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = no\n",
    "for image_name in image_name_list[:200]:\n",
    "    imageA = Image.open('../input/audio/no/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "        \n",
    "image_name_list = up\n",
    "for image_name in image_name_list[:200]:\n",
    "    imageA = Image.open('../input/audio/up/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = down\n",
    "for image_name in image_name_list[:200]:\n",
    "    imageA = Image.open('../input/audio/down/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = left\n",
    "for image_name in image_name_list[:200]:\n",
    "    imageA = Image.open('../input/audio/left/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = right\n",
    "for image_name in image_name_list[:200]:\n",
    "    imageA = Image.open('../input/audio/right/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = on\n",
    "for image_name in image_name_list[:200]:\n",
    "    imageA = Image.open('../input/audio/on/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = off\n",
    "for image_name in image_name_list[:200]:\n",
    "    imageA = Image.open('../input/audio/off/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = stop\n",
    "for image_name in image_name_list[:200]:\n",
    "    imageA = Image.open('../input/audio/stop/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = go\n",
    "for image_name in image_name_list[:200]:\n",
    "    imageA = Image.open('../input/audio/go/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "# Top 10 done\n",
    "\n",
    "# Silence 100 pictures  \n",
    "image_name_list = silence\n",
    "for image_name in image_name_list[:50]:\n",
    "    imageA = Image.open('../input/audio/silence/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1    \n",
    "\n",
    "# Unknown : 20 pictures from the rest\n",
    "    \n",
    "image_name_list = cat\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/cat/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "     \n",
    "image_name_list = four\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/four/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = house\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/house/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = nine\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/nine/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = seven\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/seven/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = two\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/two/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "\n",
    "image_name_list = bed\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/bed/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = eight\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/eight/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = one\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/one/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = sheila\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/sheila/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = three\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = plt.imread('../input/audio/three/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = zero\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/zero/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = bird\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/bird/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = dog\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/dog/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = five\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/five/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = happy\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/happy/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = marvin\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/marvin/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1 \n",
    "    \n",
    "image_name_list = six\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/six/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = tree\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/tree/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = wow\n",
    "for image_name in image_name_list[:100]:\n",
    "    imageA = Image.open('../input/audio/wow/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4800 data sets with 30 classes and 100 spectrograms in each class\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check if the end is not empty meaning that 3000 has all been transferred\n",
    "data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show one image\n",
    "plt.imshow(data[456])\n",
    "print(data[456].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min of pixel : 0.0\n",
      "max of pixel : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"min of pixel : \" + str(data[0].min()))\n",
    "print(\"max of pixel : \" + str(data[0].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#concatenate all the flattened spectrograms in order\\nfl_data = np.empty((4800,2500), dtype=np.float32)\\n\\nfor i in range(len(data)):\\n    flat = data[i].flatten()\\n    fl_data[i] = flat\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#concatenate all the flattened spectrograms in order\n",
    "fl_data = np.empty((4800,2500), dtype=np.float32)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    flat = data[i].flatten()\n",
    "    fl_data[i] = flat\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# check if transferred all\\nprint(\"size : \" + str(fl_data.shape))\\nprint(fl_data[-1])\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# check if transferred all\n",
    "print(\"size : \" + str(fl_data.shape))\n",
    "print(fl_data[-1])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(30):\n",
    "#    print(i % 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique\n",
    "def unique(list1): \n",
    "  \n",
    "    # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in list1: \n",
    "        # check if exists in unique_list or not \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x)\n",
    "    # print list \n",
    "    for x in unique_list: \n",
    "        print (x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "label = np.zeros((600,), dtype=int)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    label = np.concatenate((label, np.repeat(i, 600)))\n",
    "    \n",
    "label = np.concatenate((label, np.repeat(10, 100)))\n",
    "label = np.concatenate((label, np.repeat(11, 1200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# check uniques\n",
    "unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7300,)\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print(label.shape)\n",
    "print(type(label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label = label.reshape((4800,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(np.float64(label[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7300,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fl_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#one hot encode the lable\\nb = np.zeros((label.size, label.max()+1))\\nb[np.arange(label.size), label] = 1\\n#labels = b\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#one hot encode the lable\n",
    "b = np.zeros((label.size, label.max()+1))\n",
    "b[np.arange(label.size), label] = 1\n",
    "#labels = b\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check on prepared datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(fl_data.shape)\\nprint(labels.shape)\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(fl_data.shape)\n",
    "print(labels.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before dividing into train and test sets, let's combine so we can shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a=np.concatenate((fl_data, label), axis=1)\n",
    "#a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle\n",
    "#np.random.shuffle(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to slice the labels again\n",
    "#new_labels=a[:,-1:]#.sum()\n",
    "#new_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to slice the train again\n",
    "#train_data=a[:,:2500]\n",
    "#train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5840, 96, 96, 3), (1460, 96, 96, 3), (5840,), (1460,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, label, test_size = 0.2)\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx_train = train_data[:4000]\\nprint(\"train : \" + str(x_train.shape))\\nx_val = train_data[4000:]\\nprint(\"train validation : \" + str(x_val.shape))\\ny_train = new_labels[:4000]\\ny_train = np.int64(y_train)\\nprint(\"train label : \" + str(y_train.shape))\\ny_val = new_labels[4000:]\\ny_val = np.int64(y_val)\\nprint(\"train validation label : \" + str(y_val.shape))\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "x_train = train_data[:4000]\n",
    "print(\"train : \" + str(x_train.shape))\n",
    "x_val = train_data[4000:]\n",
    "print(\"train validation : \" + str(x_val.shape))\n",
    "y_train = new_labels[:4000]\n",
    "y_train = np.int64(y_train)\n",
    "print(\"train label : \" + str(y_train.shape))\n",
    "y_val = new_labels[4000:]\n",
    "y_val = np.int64(y_val)\n",
    "print(\"train validation label : \" + str(y_val.shape))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#change data types to df\\nx_train = pd.DataFrame(x_train)\\nx_val = pd.DataFrame(x_val)\\ny_train = pd.DataFrame(y_train)\\ny_val = pd.DataFrame(y_val)\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#change data types to df\n",
    "x_train = pd.DataFrame(x_train)\n",
    "x_val = pd.DataFrame(x_val)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_val = pd.DataFrame(y_val)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train[0][0][0]))\n",
    "y_train = np.int32(y_train)\n",
    "print(type(y_train[0]))\n",
    "print(type(x_val[0][0][0]))\n",
    "y_val = np.int32(y_val)\n",
    "print(type(y_val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5840, 96, 96, 3)\n",
      "(5840,)\n",
      "(1460, 96, 96, 3)\n",
      "(1460,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Helper f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  # Input Layer\n",
    "    input_layer = tf.reshape(features, [-1, 96, 96, 3])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2) \n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Dense Layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 36864])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=12)\n",
    "\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    # here we define how we calculate our accuracy\n",
    "    # if you want to monitor your training accuracy you need these two lines\n",
    "    accuracy = tf.metrics.accuracy(labels=labels, predictions=predictions['classes'], name='acc_op')\n",
    "    tf.summary.scalar('accuracy', accuracy[1])\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        tf.identity(accuracy[1], name='train_accuracy')\n",
    "        tf.summary.scalar('train_accuracy', accuracy[1])\n",
    "        eval_metric_ops = {'train_accuracy':accuracy}\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    tf.identity(accuracy[1], name='val_accuracy')\n",
    "    tf.summary.scalar('val_accuracy', accuracy[1])\n",
    "    eval_metric_ops = {'val_accuracy':accuracy}\n",
    "    #eval_metric_ops = {\n",
    "    #  \"accuracy\": tf.metrics.accuracy(\n",
    "    #      labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_feature_columns():\n",
    "    return set([tf.feature_column.numeric_column('pixels', shape=9216)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predict_input_fn(features, labels, batch_size):\n",
    "    predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x=features,\n",
    "        y=labels,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    return predict_input_fn\n",
    "\n",
    "def create_training_input_fn(features, labels, batch_size):\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x=features,\n",
    "        y=labels,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "    return train_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6100f589aaca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidation_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtraining_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidation_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "training_examples = x_train\n",
    "validation_examples = x_val\n",
    "training_targets = y_train\n",
    "validation_targets = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hub_classification_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    hidden_units,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "\n",
    "    periods = 10\n",
    "    steps_per_period = steps / periods \n",
    "    \n",
    "    predict_training_input_fn = create_predict_input_fn(training_examples, training_targets, batch_size)\n",
    "    predict_validation_input_fn = create_predict_input_fn(validation_examples, validation_targets, batch_size)\n",
    "  \n",
    "    training_input_fn = create_training_input_fn(training_examples, training_targets, batch_size)\n",
    "    predict_training_input_fn = create_predict_input_fn(training_examples, training_targets, batch_size)\n",
    "    \n",
    "    predict_validation_input_fn = create_predict_input_fn(validation_examples, validation_targets, batch_size)\n",
    "    training_input_fn = create_training_input_fn(training_examples, training_targets, batch_size)\n",
    "  \n",
    "    feature_columns = [tf.feature_column.numeric_column('pixels', shape=9216)]\n",
    "\n",
    "    my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "    classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn,\n",
    "    model_dir=\"./mode_CNN_6\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    print(\"Training model...\")\n",
    "    print(\"LogLoss error (on validation data):\")\n",
    "    training_errors = []\n",
    "    validation_errors = []\n",
    "    training_accu = []\n",
    "    validation_accu = []\n",
    "    for period in range (0, periods):\n",
    "        classifier.train(\n",
    "            input_fn=training_input_fn,\n",
    "            steps=steps_per_period,\n",
    "        )\n",
    "        training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
    "        training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
    "        training_pred_class_id = np.array([item['classes'] for item in training_predictions])\n",
    "        training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,12) #change class number\n",
    "\n",
    "        validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
    "        validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
    "        validation_pred_class_id = np.array([item['classes'] for item in validation_predictions])\n",
    "        validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,12) #change class number\n",
    "\n",
    "        # Compute training and validation errors.\n",
    "        training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
    "        #training_acc = metrics.accuracy_score(training_targets, training_predictions)\n",
    "        validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
    "        #validation_acc = metrics.accuracy_score(validation_targets, validation_predictions)\n",
    "        # Occasionally print the current loss.\n",
    "        print(\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
    "        # Add the loss metrics from this period to our list.\n",
    "        training_errors.append(training_log_loss)\n",
    "        validation_errors.append(validation_log_loss)\n",
    "        #training_accu.append(training_acc)\n",
    "        #validation_accu.append(validation_acc)\n",
    "        \n",
    "    print(\"Model training finished.\")\n",
    "    # Remove event files to save disk space.\n",
    "    _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
    "\n",
    "    # Calculate final predictions (not probabilities, as above).\n",
    "    final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
    "    final_predictions = np.array([item['classes'] for item in final_predictions])\n",
    "\n",
    "\n",
    "    accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
    "    print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
    "\n",
    "    # Output a graph of loss metrics over periods.\n",
    "    plt.ylabel(\"LogLoss\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"LogLoss vs. Periods\")\n",
    "    plt.plot(training_errors, label=\"training\")\n",
    "    plt.plot(validation_errors, label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    #plt.ylabel(\"Accuracy\")\n",
    "    #plt.xlabel(\"Periods\")\n",
    "    #plt.title(\"Accuracy vs. Periods\")\n",
    "    #plt.plot(training_accu, label=\"training\")\n",
    "    #plt.plot(validation_accu, label=\"validation\")\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    # Output a plot of the confusion matrix.\n",
    "    cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
    "    # Normalize the confusion matrix by row (i.e by the number of samples\n",
    "    # in each class).\n",
    "    cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "    ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
    "    ax.set_aspect(1)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.show()\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 96, 96, 3)\n",
      "1460\n"
     ]
    }
   ],
   "source": [
    "#len(set(training_targets))\n",
    "#validation_targets\n",
    "print(validation_examples.shape)\n",
    "print(len(validation_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(set(validation_targets)))\n",
    "print(len(set(training_targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './mode_CNN_6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f25f10bc5c0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.4573841, step = 3001\n",
      "INFO:tensorflow:Saving checkpoints for 3100 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.6548435.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 00 : 10.36\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3100 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.5382368, step = 3101\n",
      "INFO:tensorflow:Saving checkpoints for 3200 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.7585672.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 01 : 9.94\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3200 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.3650254, step = 3201\n",
      "INFO:tensorflow:Saving checkpoints for 3300 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.7500727.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 02 : 9.63\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3300 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.3176302, step = 3301\n",
      "INFO:tensorflow:Saving checkpoints for 3400 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.18710433.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 03 : 9.91\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3400 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.34249642, step = 3401\n",
      "INFO:tensorflow:Saving checkpoints for 3500 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.6155459.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 04 : 10.41\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3500 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.63901025, step = 3501\n",
      "INFO:tensorflow:Saving checkpoints for 3600 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.3857982.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 05 : 10.17\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3600 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.38510108, step = 3601\n",
      "INFO:tensorflow:Saving checkpoints for 3700 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.5449185.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3700\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 06 : 10.43\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3700\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3700 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.26927292, step = 3701\n",
      "INFO:tensorflow:Saving checkpoints for 3800 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.8206687.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 07 : 10.55\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3800 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.20049332, step = 3801\n",
      "INFO:tensorflow:Saving checkpoints for 3900 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.21290903.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3900\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3900\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 08 : 9.79\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-3900\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3900 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.45669076, step = 3901\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into ./mode_CNN_6/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.28756234.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 09 : 9.25\n",
      "Model training finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Final accuracy (on validation data): 0.73\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = train_hub_classification_model(\n",
    "    learning_rate=0.001,\n",
    "    steps=1000,\n",
    "    batch_size=10,\n",
    "    hidden_units=[100, 100],\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;31m# resolution to succeed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mpython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;31m# pylint: enable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-52-e4615a684824>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-52-e4615a684824>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './mode_CNN_6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7febcc4b1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn,\n",
    "    model_dir=\"./mode_CNN_6\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_test_input_fn(features, batch_size=1, num_epochs=None):\n",
    "    raw_features = features\n",
    "    ds = Dataset.from_tensor_slices((raw_features))\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    features = ds.make_one_shot_iterator().get_next()\n",
    "    return features\n",
    "\n",
    "predict_test_input_fn = lambda: my_test_input_fn(\n",
    "    test_images,\n",
    "    num_epochs=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pict_path = '../input/audio_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imread('../input/audio_test/clip_000044442.png').shape==(96,96,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-divide into 10,000 test files to prevent tensor 2MB error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-e80ff81970e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mall_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pict_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'.png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[:10000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'a' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[10000:20000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'b' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[20000:30000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'c' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[30000:40000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'd' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[40000:50000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'e' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[50000:60000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'f' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[60000:70000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'g' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[70000:80000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'h' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[80000:90000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'i' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[90000:100000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'j' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[100000:110000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'k' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[110000:120000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'l' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[120000:130000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'm' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[130000:140000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'n' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[140000:150000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'o' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mode_CNN_6/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[150000:]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (96,96,3)):\n",
    "        test_images.append(cv2.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((96,96,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'p' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pred Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'yes':0, 'no':1, 'up':2, 'down':3, 'left':4, 'right':5, 'on':6, 'off':7, \n",
    "              'stop':8, 'go':9, 'silence':10, 'unknown':11}\n",
    "\n",
    "reverse_dict = {v: k for k, v in label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clip_25f96ade6.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clip_ac8fa1682.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clip_cdadf318a.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clip_7419f0d7e.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clip_9e83292d5.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clip_00f803721.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clip_aafb5a6d9.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clip_0dee755a2.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clip_8070bb404.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>clip_b3bef71f6.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>clip_b94577f1e.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>clip_4fd22b958.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>clip_b3a950c47.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>clip_c87b8ff71.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>clip_a0039589b.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>clip_c7c4eaf1d.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>clip_f6ff9e9b5.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>clip_bfc01d316.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>clip_6984491f2.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>clip_e51432c10.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>clip_fe6ce335c.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>clip_3e0ed2f0a.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>clip_c9f89457a.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>clip_cc3cc2827.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>clip_7cc8f3c63.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>clip_3070880b8.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>clip_6f112fd1e.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>clip_fb1febbcd.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>clip_f8de61a7d.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>clip_95442c1ad.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8508</th>\n",
       "      <td>clip_a409e7c59.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8509</th>\n",
       "      <td>clip_17a284d62.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8510</th>\n",
       "      <td>clip_ccc2cf3a0.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>clip_a022d6b0f.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>clip_e80799edd.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>clip_590b569d6.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>clip_f307872c0.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>clip_97bddae19.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8516</th>\n",
       "      <td>clip_9a3d8e307.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517</th>\n",
       "      <td>clip_192c4c8b7.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518</th>\n",
       "      <td>clip_aa5f97a5e.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8519</th>\n",
       "      <td>clip_4d132f74e.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8520</th>\n",
       "      <td>clip_f213e6669.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8521</th>\n",
       "      <td>clip_cceddadaf.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8522</th>\n",
       "      <td>clip_e4409418c.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8523</th>\n",
       "      <td>clip_3405ed2d1.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8524</th>\n",
       "      <td>clip_4b2d5d22f.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>clip_f7d8f27d3.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>clip_08e2f8e78.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>clip_1374683d1.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>clip_135bc0720.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>clip_b903ccfbb.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8530</th>\n",
       "      <td>clip_d63120591.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8531</th>\n",
       "      <td>clip_c0f642e3c.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8532</th>\n",
       "      <td>clip_82890a52e.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8533</th>\n",
       "      <td>clip_fd9ac86a1.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8534</th>\n",
       "      <td>clip_61a6cc3a0.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8535</th>\n",
       "      <td>clip_701cc7171.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8536</th>\n",
       "      <td>clip_38d480e69.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8537</th>\n",
       "      <td>clip_7843dfbdb.wav</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158538 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   fname    label\n",
       "0     clip_25f96ade6.wav  silence\n",
       "1     clip_ac8fa1682.wav  silence\n",
       "2     clip_cdadf318a.wav  silence\n",
       "3     clip_7419f0d7e.wav    right\n",
       "4     clip_9e83292d5.wav       on\n",
       "5     clip_00f803721.wav  silence\n",
       "6     clip_aafb5a6d9.wav       on\n",
       "7     clip_0dee755a2.wav       on\n",
       "8     clip_8070bb404.wav  unknown\n",
       "9     clip_b3bef71f6.wav  silence\n",
       "10    clip_b94577f1e.wav  silence\n",
       "11    clip_4fd22b958.wav      off\n",
       "12    clip_b3a950c47.wav  silence\n",
       "13    clip_c87b8ff71.wav  silence\n",
       "14    clip_a0039589b.wav  silence\n",
       "15    clip_c7c4eaf1d.wav  silence\n",
       "16    clip_f6ff9e9b5.wav  silence\n",
       "17    clip_bfc01d316.wav  unknown\n",
       "18    clip_6984491f2.wav  silence\n",
       "19    clip_e51432c10.wav     down\n",
       "20    clip_fe6ce335c.wav      yes\n",
       "21    clip_3e0ed2f0a.wav  silence\n",
       "22    clip_c9f89457a.wav  silence\n",
       "23    clip_cc3cc2827.wav  silence\n",
       "24    clip_7cc8f3c63.wav  silence\n",
       "25    clip_3070880b8.wav      off\n",
       "26    clip_6f112fd1e.wav      off\n",
       "27    clip_fb1febbcd.wav      yes\n",
       "28    clip_f8de61a7d.wav    right\n",
       "29    clip_95442c1ad.wav  silence\n",
       "...                  ...      ...\n",
       "8508  clip_a409e7c59.wav     down\n",
       "8509  clip_17a284d62.wav  silence\n",
       "8510  clip_ccc2cf3a0.wav  silence\n",
       "8511  clip_a022d6b0f.wav  silence\n",
       "8512  clip_e80799edd.wav  silence\n",
       "8513  clip_590b569d6.wav  unknown\n",
       "8514  clip_f307872c0.wav  silence\n",
       "8515  clip_97bddae19.wav  silence\n",
       "8516  clip_9a3d8e307.wav  unknown\n",
       "8517  clip_192c4c8b7.wav  silence\n",
       "8518  clip_aa5f97a5e.wav  silence\n",
       "8519  clip_4d132f74e.wav    right\n",
       "8520  clip_f213e6669.wav      off\n",
       "8521  clip_cceddadaf.wav  silence\n",
       "8522  clip_e4409418c.wav       on\n",
       "8523  clip_3405ed2d1.wav       go\n",
       "8524  clip_4b2d5d22f.wav  silence\n",
       "8525  clip_f7d8f27d3.wav  silence\n",
       "8526  clip_08e2f8e78.wav  silence\n",
       "8527  clip_1374683d1.wav  silence\n",
       "8528  clip_135bc0720.wav    right\n",
       "8529  clip_b903ccfbb.wav       on\n",
       "8530  clip_d63120591.wav  silence\n",
       "8531  clip_c0f642e3c.wav  unknown\n",
       "8532  clip_82890a52e.wav  silence\n",
       "8533  clip_fd9ac86a1.wav  silence\n",
       "8534  clip_61a6cc3a0.wav       on\n",
       "8535  clip_701cc7171.wav  unknown\n",
       "8536  clip_38d480e69.wav  silence\n",
       "8537  clip_7843dfbdb.wav     stop\n",
       "\n",
       "[158538 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0 = pd.read_csv(\"./speech_\" + 'a' + \".csv\",sep=\",\")\n",
    "d1 = pd.read_csv(\"./speech_\" + 'b' + \".csv\",sep=\",\")\n",
    "d2 = pd.read_csv(\"./speech_\" + 'c' + \".csv\",sep=\",\")\n",
    "d3 = pd.read_csv(\"./speech_\" + 'd' + \".csv\",sep=\",\")\n",
    "d4 = pd.read_csv(\"./speech_\" + 'e' + \".csv\",sep=\",\")\n",
    "d5 = pd.read_csv(\"./speech_\" + 'f' + \".csv\",sep=\",\")\n",
    "d6 = pd.read_csv(\"./speech_\" + 'g' + \".csv\",sep=\",\")\n",
    "d7 = pd.read_csv(\"./speech_\" + 'h' + \".csv\",sep=\",\")\n",
    "d8 = pd.read_csv(\"./speech_\" + 'i' + \".csv\",sep=\",\")\n",
    "d9 = pd.read_csv(\"./speech_\" + 'j' + \".csv\",sep=\",\")\n",
    "d10 = pd.read_csv(\"./speech_\" + 'k' + \".csv\",sep=\",\")\n",
    "d11 = pd.read_csv(\"./speech_\" + 'l' + \".csv\",sep=\",\")\n",
    "d12 = pd.read_csv(\"./speech_\" + 'm' + \".csv\",sep=\",\")\n",
    "d13 = pd.read_csv(\"./speech_\" + 'n' + \".csv\",sep=\",\")\n",
    "d14 = pd.read_csv(\"./speech_\" + 'o' + \".csv\",sep=\",\")\n",
    "d15 = pd.read_csv(\"./speech_\" + 'p' + \".csv\",sep=\",\")\n",
    "\n",
    "df = [d0,d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12,d13,d14,d15]\n",
    "dx = pd.concat(df)\n",
    "\n",
    "dx = dx.replace({\"label\": reverse_dict})\n",
    "\n",
    "dx.to_csv('submission_v2.csv', index=False)\n",
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
